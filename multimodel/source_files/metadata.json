{"1": {"page": 0, "image": "Im1", "block": 5, "image_dim": [2714, 1803], "image_info": "<image: DeviceRGB, width: 2714, height: 1803, bpc: 8>", "image_title": "Fig. 1: The trends in the number of LLM models introduced\nover the years.\n", "image_file": "Im1_5.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im1_5.png"}, "2": {"page": 2, "image": "Im3", "block": 67, "image_dim": [3028, 2963], "image_info": "<image: Indexed(210,DeviceRGB), width: 3028, height: 2963, bpc: 8>", "image_title": "Fig. 3: A broader overview of LLMs, dividing LLMs into five branches: 1. Training 2. Inference 3. Evaluation 4. Applications\n5. Challenges\n", "image_file": "Im3_67.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im3_67.png"}, "3": {"page": 5, "image": "Im4", "block": 328, "image_dim": [598, 213], "image_info": "<image: DeviceRGB, width: 598, height: 213, bpc: 8>", "image_title": "Fig. 4: An example of attention patterns in language models,\nimage is taken from [91].\n", "image_file": "Im4_328.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im4_328.png"}, "4": {"page": 5, "image": "Im5", "block": 332, "image_dim": [536, 163], "image_info": "<image: DeviceRGB, width: 598, height: 213, bpc: 8>", "image_title": "Fig. 4: An example of attention patterns in language models,\nimage is taken from [91].\n", "image_file": "Im5_332.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im5_332.png"}, "5": {"page": 6, "image": "Im6", "block": 336, "image_dim": [1880, 1280], "image_info": "<image: Indexed(253,DeviceRGB), width: 1880, height: 1280, bpc: 8>", "image_title": "Fig. 6: A basic flow diagram depicting various stages of LLMs from pre-training to prompting/utilization. Prompting LLMs\nto generate responses is possible at different training stages like pre-training, instruction-tuning, or alignment tuning.\n", "image_file": "Im6_336.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im6_336.png"}, "6": {"page": 7, "image": "Im7", "block": 429, "image_dim": [881, 314], "image_info": "<image: DeviceRGB, width: 881, height: 314, bpc: 8>", "image_title": "Fig. 7: Unified text-to-text training example, source image\nfrom [10].\n", "image_file": "Im7_429.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im7_429.png"}, "7": {"page": 8, "image": "Im8", "block": 463, "image_dim": [654, 406], "image_info": "<image: DeviceRGB, width: 654, height: 406, bpc: 8>", "image_title": "Fig. 8: The image is the article of [104], showing an example\nof PanGu-\u03b1 architecture.\n", "image_file": "Im8_463.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im8_463.png"}, "8": {"page": 9, "image": "Im9", "block": 524, "image_dim": [789, 382], "image_info": "<image: DeviceRGB, width: 789, height: 382, bpc: 8>", "image_title": "Fig. 9: The BLOOM architecture example sourced from [13].\n", "image_file": "Im9_524.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im9_524.png"}, "9": {"page": 11, "image": "Im10", "block": 634, "image_dim": [751, 509], "image_info": "<image: DeviceRGB, width: 751, height: 509, bpc: 8>", "image_title": "Fig. 10: This example illustrates the PanGu-\ufffd architecture,\nas depicted in the image sourced from [129].\n", "image_file": "Im10_634.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im10_634.png"}, "10": {"page": 11, "image": "Im11", "block": 654, "image_dim": [787, 392], "image_info": "<image: DeviceRGB, width: 751, height: 509, bpc: 8>", "image_title": "Fig. 10: This example illustrates the PanGu-\ufffd architecture,\nas depicted in the image sourced from [129].\n", "image_file": "Im11_654.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im11_654.png"}, "11": {"page": 17, "image": "Im12", "block": 947, "image_dim": [840, 480], "image_info": "<image: Indexed(191,DeviceRGB), width: 840, height: 480, bpc: 8>", "image_title": "Fig. 12: A flow diagram of Retrieval Augmented LLMs. The\nretriever extracts a similar context to the input and forwards\nit to the LLM either in simple language or encoded through\nFusion-in-Decoder (FiD). Depending on the task, retrieval and\ngeneration may repeat multiple times.\n", "image_file": "Im12_947.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im12_947.png"}, "12": {"page": 18, "image": "Im13", "block": 1028, "image_dim": [820, 740], "image_info": "<image: DeviceRGB, width: 820, height: 740, bpc: 8>", "image_title": "Fig. 13: A basic flow diagram of tool augmented LLMs. Given\nan input and a set of available tools, the model generates a\nplan to complete the task. The tool augmented LLMs utilize\ndifferent modules iteratively, such as retriever, tool execution,\nread-write to memory, feedback, etc., depending on the task.\n", "image_file": "Im13_1028.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im13_1028.png"}, "13": {"page": 20, "image": "Im14", "block": 1079, "image_dim": [1580, 465], "image_info": "<image: Indexed(176,DeviceRGB), width: 1580, height: 465, bpc: 8>", "image_title": "Fig. 14: Illustration of parameter-efficient fine-tuning paradigms, where x is input and h is hidden state, figure courtesy [38].\n", "image_file": "Im14_1079.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im14_1079.png"}, "14": {"page": 24, "image": "Im15", "block": 1288, "image_dim": [996, 274], "image_info": "<image: DeviceRGB, width: 996, height: 274, bpc: 8>", "image_title": "Fig. 15: A distribution of datasets proposed for different NLP tasks. We include only the tasks for which at least 20 datasets\nhave already been proposed.\n", "image_file": "Im15_1288.png", "image_path": "/home/sudouser/stage-code/nlp/LlamaIndex/multimodel/source_files/Im15_1288.png"}}